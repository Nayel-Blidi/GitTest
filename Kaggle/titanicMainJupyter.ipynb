{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0         0       3    male  22.0      1      0   7.2500        S\n",
      "1         1       1  female  38.0      1      0  71.2833        C\n",
      "2         1       3  female  26.0      0      0   7.9250        S\n",
      "3         1       1  female  35.0      1      0  53.1000        S\n",
      "4         0       3    male  35.0      0      0   8.0500        S\n",
      "   Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
      "0       3  34.5      0      0   7.8292           0         1           0   \n",
      "1       3  47.0      1      0   7.0000           1         0           0   \n",
      "2       2  62.0      0      0   9.6875           0         1           0   \n",
      "3       3  27.0      0      0   8.6625           0         1           0   \n",
      "4       3  22.0      1      1  12.2875           1         0           0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0           1           0  \n",
      "1           0           1  \n",
      "2           1           0  \n",
      "3           0           1  \n",
      "4           0           1  \n",
      "0\n",
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Survived\n",
      "0       3    male  34.5      0      0   7.8292        Q         0\n",
      "1       3  female  47.0      1      0   7.0000        S         1\n",
      "2       2    male  62.0      0      0   9.6875        Q         0\n",
      "3       3    male  27.0      0      0   8.6625        S         0\n",
      "4       3  female  22.0      1      1  12.2875        S         1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# current_folder_path = os.path.dirname(os.path.abspath(__file__))\n",
    "current_folder_path = os.path.abspath('')\n",
    "\n",
    "# Training datatset cleaning\n",
    "train_data = pd.read_csv(f\"{current_folder_path}/train.csv\")\n",
    "# Getting rid of too specific string values\n",
    "train_data = train_data.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "\n",
    "# Getting rid of NaN values among the remaining columns\n",
    "# nan_count = train_data.isna().sum().sum()\n",
    "# print(nan_count)\n",
    "train_data.dropna(axis=0, inplace=True)\n",
    "print(train_data.head())\n",
    "\n",
    "train_labels = train_data[[\"Survived\"]]\n",
    "\n",
    "train_features = train_data.drop(columns=[\"Survived\"])\n",
    "train_features = pd.get_dummies(train_features)\n",
    "\n",
    "\n",
    "# Testing datatset cleaning\n",
    "test_data = pd.read_csv(f\"{current_folder_path}/test.csv\")\n",
    "submission_data = pd.get_dummies(test_data.fillna(value=0).drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]))\n",
    "# print(train_features.columns.values)\n",
    "submission_data = submission_data.reindex(columns=train_features.columns.values)\n",
    "print(submission_data.head())\n",
    "print(np.sum(submission_data.isna().to_numpy()))\n",
    "\n",
    "answer = pd.read_csv(f\"{current_folder_path}/gender_submission.csv\")[[\"Survived\"]]\n",
    "test_data[[\"Survived\"]] = answer[[\"Survived\"]]\n",
    "\n",
    "# Getting rid of too specific string values\n",
    "test_data = test_data.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "\n",
    "# Getting rid of NaN values among the remaining columns\n",
    "test_data.dropna(axis=0, inplace=True)\n",
    "print(test_data.head())\n",
    "\n",
    "test_labels = test_data[[\"Survived\"]]\n",
    "\n",
    "test_features = test_data.drop(columns=[\"Survived\"])\n",
    "test_features = pd.get_dummies(test_features)\n",
    "\n",
    "# print(test_data.head())\n",
    "# print(test_features.tail())\n",
    "# print(test_labels.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train_features \n",
      "    Pclass   Age  SibSp  Parch  Fare  Sex_female  Sex_male  Embarked_C  \\\n",
      "0       3  22.0      1      0  7.25           0         1           0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0           0           1   \n",
      " train_labels \n",
      "    Survived\n",
      "0         0\n",
      "\n",
      " test_features \n",
      "    Pclass   Age  SibSp  Parch    Fare  Sex_female  Sex_male  Embarked_C  \\\n",
      "0       3  34.5      0      0  7.8292           0         1           0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0           1           0   \n",
      " test_labels \n",
      "    Survived\n",
      "0         0\n",
      "\n",
      " test_features \n",
      "    Pclass   Age  SibSp  Parch    Fare  Sex_female  Sex_male  Embarked_C  \\\n",
      "0       3  34.5      0      0  7.8292           0         1           0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0           1           0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n train_features \\n\", train_features.head(1), \"\\n train_labels \\n\", train_labels.head(1))\n",
    "print(\"\\n test_features \\n\", test_features.head(1), \"\\n test_labels \\n\", test_labels.head(1))\n",
    "print(\"\\n test_features \\n\", submission_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN structure definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size= hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.layer1 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.layer2 = nn.Linear(hidden_size//2, hidden_size//4)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size//2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_size//4)\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size//4, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "        self.dropout = nn.Dropout1d(p=0.1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.output_layer(x)  \n",
    "        #x = self.relu(x)    \n",
    "        x = self.sigmoid(x)\n",
    "        return x        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891, 10]) torch.Size([891, 1]) torch.Size([331, 10]) torch.Size([331, 1])\n"
     ]
    }
   ],
   "source": [
    "train_features = torch.from_numpy(train_features.to_numpy()).float()\n",
    "train_labels = torch.from_numpy(train_labels.to_numpy()).float()\n",
    "test_features = torch.from_numpy(test_features.to_numpy()).float()\n",
    "test_labels = torch.from_numpy(test_labels.to_numpy()).float()\n",
    "submission_features = torch.from_numpy(submission_data.to_numpy()).float()\n",
    "\n",
    "train_features = F.normalize(train_features)\n",
    "test_features = F.normalize(test_features)\n",
    "\n",
    "print(train_features.size(), train_labels.size(), test_features.size(), test_labels.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git\\GitTest\\Kaggle\\titanicMainJupyter.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(train_features)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, train_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\BLIDI\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\BLIDI\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\BLIDI\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n\u001b[0;32m   3096\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3098\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight, reduction_enum)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "m, n = train_features.shape\n",
    "input_size = n\n",
    "print(input_size)\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimize = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "model.train() \n",
    "running_loss = 0.0\n",
    "\n",
    "losses_list = []\n",
    "# num_epochs = int(input(\"Number of epochs : \"))  \n",
    "num_epochs = 500     \n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_features)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    losses_list.append(loss.item())\n",
    "\n",
    "print(f\"Epoch {epoch+1}, Loss: {running_loss}\")\n",
    "# print(np.round(losses_list[::10], 6))\n",
    "p = (sns.lineplot(losses_list))\n",
    "# p.label(x=\"Epochs\", y=\"Loss\", title=\"Losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (331x10 and 11x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git\\GitTest\\Kaggle\\titanicMainJupyter.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(test_features) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(outputs[\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mT)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m#predicted = torch.round(outputs.data)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m#_, predicted = torch.max(outputs.data, 1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BLIDI\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Git\\GitTest\\Kaggle\\titanicMainJupyter.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layer(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/GitTest/Kaggle/titanicMainJupyter.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n",
      "File \u001b[1;32mc:\\Users\\BLIDI\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\BLIDI\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (331x10 and 11x64)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_features) \n",
    "    print(outputs[0:10].T)\n",
    "    #predicted = torch.round(outputs.data)\n",
    "    #_, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = torch.round(outputs.data)\n",
    "    # predicted = np.round(outputs.numpy())\n",
    "    total += test_labels.size(0)\n",
    "    # correct += (predicted.numpy() == test_labels.numpy().T).sum().item()\n",
    "    correct += (predicted == test_labels).sum().item()        \n",
    "    \n",
    "    print(predicted.numpy()[0:10].T, test_labels.numpy().T[0, 0:10])\n",
    "    #correct += (predicted == test_labels.numpy().T[0]).sum().item()\n",
    "\n",
    "    \n",
    "# print(np.unique(predicted.numpy(), return_counts=True))\n",
    "# print(np.unique(test_labels.numpy(), return_counts=True))\n",
    "# print(predicted.numpy()[0:10], test_labels.numpy().T[0, 0:10])\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_0  \\\n",
      "0       3  34.5      0      0   7.8292           0         1         NaN   \n",
      "1       3  47.0      1      0   7.0000           1         0         NaN   \n",
      "2       2  62.0      0      0   9.6875           0         1         NaN   \n",
      "3       3  27.0      0      0   8.6625           0         1         NaN   \n",
      "4       3  22.0      1      1  12.2875           1         0         NaN   \n",
      "\n",
      "   Embarked_C  Embarked_Q  Embarked_S  \n",
      "0           0           1           0  \n",
      "1           0           0           1  \n",
      "2           0           1           0  \n",
      "3           0           0           1  \n",
      "4           0           0           1  \n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892       NaN\n",
       "1          893       NaN\n",
       "2          894       NaN\n",
       "3          895       NaN\n",
       "4          896       NaN"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(submission_data.head())\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(submission_features) \n",
    "    print(outputs[0:10])\n",
    "    submission_prediction = torch.round(outputs.data)\n",
    "    print(submission_prediction[0:10])\n",
    "\n",
    "    \n",
    "prediction_array = submission_prediction.numpy()\n",
    "submission_dataframe = pd.DataFrame(pd.read_csv(f\"{current_folder_path}/test.csv\")[[\"PassengerId\"]])\n",
    "submission_dataframe[[\"Survived\"]] = pd.DataFrame(submission_prediction)\n",
    "\n",
    "submission_dataframe.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
