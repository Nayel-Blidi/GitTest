# %%

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import cv2 

from sklearn.model_selection import train_test_split
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from torchvision import datasets, transforms

import os
import sys

main_path = os.path.abspath("")
input_data_path = main_path
output_model_path = main_path + "/Models"
print(f"\n> Root: {main_path}\n")

# %% DATA LOADING

data = np.load(input_data_path + "/images_malware.npz", allow_pickle=True)
data = data["arr"]

arrays = np.expand_dims(np.stack([datapoint[0] for datapoint in data]), axis=1)
labels = np.array([np.stack([datapoint[1] for datapoint in data])]).T
num_classes = np.max(labels) + 1 
# Perform one-hot encoding
labels = np.squeeze(np.eye(num_classes)[labels])

# print(arrays.shape)
# print(labels.shape)

batch_size, in_channels, height, width = arrays.shape
output_size = np.shape(labels)[-1]

print("> batch_size, in_channels, height, width, output_size:")
print("\t", batch_size, "\t" ,in_channels, "\t", height, "\t", width, "\t", output_size)

# %% PRE PROCESSING

print("> in_channels, output_size:\n", "\t", in_channels, "\t", output_size)

X_train, X_test, Y_train, Y_test = train_test_split(arrays, labels, test_size=0.25)
print("> X_train.shape, Y_train.shape, X_test.shape, Y_test.shape:")
print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)

input_size = X_train.shape[0]

mean = np.mean(arrays, axis=0)
std = np.std(arrays, axis=0)

normalize = transforms.Normalize(mean=mean, std=std)

train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).float())
train_dataset.transform = transforms.Compose([normalize])
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).float())
test_dataset.transform = transforms.Compose([normalize])
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

# %% MODEL
class CNN(nn.Module):
    def __init__(self, in_channels=1, output_size=25, filters=16, hidden_layer=128):
        super(CNN, self).__init__()
        
        self.in_channels = in_channels
        self.outputsize = output_size
        self.filters = filters
        self.hidden_layer = hidden_layer

        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=filters, kernel_size=3, padding=1, stride=1)
        self.conv2 = nn.Conv2d(in_channels=filters, out_channels=4*filters, kernel_size=3, padding=1, stride=1)

        self.linear1 = nn.Linear(self.num_flat_features(torch.randn(in_channels, filters, 32, 32)), self.hidden_layer)
        self.linear2 = nn.Linear(self.hidden_layer, out_features=output_size)

    def forward(self, x):
        
        x = self.relu(self.conv1(x))

        x = self.maxpool(x)

        x = self.relu(self.conv2(x))
        
        x = x.view(-1, self.num_flat_features(x))

        x = self.linear1(x)
        x = self.relu(x)
        x = self.linear2(x)

        return x

    #Flattens along dim>=1
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


# %% MODEL TRAINING
if __name__ == "__main__" and "training" in sys.argv:

    model = CNN(in_channels=in_channels, 
                output_size=output_size,
    )
    model_name = "CNN"

    criterion = nn.CrossEntropyLoss()
    # criterion = nn.BCEWithLogitsLoss()

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    model.train() 

    running_loss = 0.0
    losses_list = []
    #num_epochs = int(input("Number of epochs : "))    
    num_epochs = int(input("Number of training epochs: ") or 100) # User input or 100 nb if epochs
    for epoch in tqdm(range(num_epochs)):

        for inputs, targets in train_dataloader:

            optimizer.zero_grad()  
            outputs = model(inputs)  

            loss = criterion(outputs, targets)

            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            losses_list.append(loss.item())

    print(f"Final loss: {loss.item()}")

    plt.semilogy(losses_list)
    plt.title("Training losses")
    plt.xlabel("Epochs")
    plt.ylabel("Running loss")
    plt.savefig(f"{output_model_path}/Loss_{model_name}_{num_epochs}e.png")
    plt.show()

    torch.save(model.state_dict(), f"{output_model_path}/{model_name}_{num_epochs}e.pth")
    print("Finished training, model saved")

# %% MODEL TESTING
if __name__ == "__main__" and "testing" in sys.argv:
    
    try:
        model = CNN(in_channels=in_channels, output_size=output_size)
        model.load_state_dict(torch.load(f"{output_model_path}/CNN_{num_epochs}e.pth"))
        model_loaded = "Currently trained model used "
    except:
        num_epochs = int(input("Number of training epochs: ") or 100) # User input or 100 nb if epochs
        model = CNN(in_channels=in_channels, output_size=output_size)
        model.load_state_dict(torch.load(f"{output_model_path}/CNN_{num_epochs}e.pth"))
        model_loaded = f"{num_epochs}e model loaded"

    # Loading pre trained model if available
    if (False or ("pretrained" in sys.argv)):
        try:
            model.load_state_dict(torch.load(f"{output_model_path}/CNN_10e.pth"))
            model_loaded = "10 epochs pre trained model loaded"
        except:
            None
        try:
            model.load_state_dict(torch.load(f"{output_model_path}/CNN_100e.pth"))
            model_loaded = "100 epochs pre trained model loaded"
        except:
            None
        try:
            model.load_state_dict(torch.load(f"{output_model_path}/CNN_1000e.pth"))
            model_loaded = "1k pre trained model loaded"
        except:
            None
        try:
            model.load_state_dict(torch.load(f"{output_model_path}/CNN_10000e.pth"))
            model_loaded = "10k pre trained model loaded"
        except:
            None
        try:
            model.load_state_dict()
            model.load_state_dict(torch.load(f"{output_model_path}/CNN_20000e.pth"))
            model_loaded = "20k pre trained model loaded"
        except:
            None
    print(model_loaded)

    model.eval()
    with torch.no_grad():
        for test_features, test_labels in test_dataloader: # Tests real accuracy

            test_labels = torch.argmax(test_labels, dim=1).numpy()

            test_predicted = torch.argmax(model(test_features), dim=1).numpy()

            test_success = np.sum(np.equal(test_predicted, test_labels))
            print(f"testing accuracy: {test_success/test_predicted.shape[-1]:.4f}")

        for train_features, train_labels in train_dataloader: # Tests overfitting

            train_labels = torch.argmax(train_labels, dim=1).numpy()

            train_predicted = torch.argmax(model(train_features), dim=1).numpy()
            train_success = np.sum(np.equal(train_predicted, train_labels))
            print(f"training accuracy: {train_success/train_predicted.shape[-1]:4f}")

    # predict_values, pred_counts = np.unique(test_predicted, return_counts=True)
    # labels_values, test_counts = np.unique(test_labels, return_counts=True)
    # print(pred_counts)
    # print(test_counts)


